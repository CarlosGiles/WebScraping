{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encontrar elementos dentro del código HTML\n",
    "\n",
    "Como ya habíamos hecho, abrimos las herramientas de desarrollador en el navegador, ya sea con **control + F12** o con **click derecho -> inspeccionar** en la [página del periódico: sun](https://www.thesun.co.uk/sport/football/).\n",
    "\n",
    "Dentro de las herramientas de desarrollador, hacemos click en la siguiente opción:\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/92232878/182712534-32876ce5-223c-4a05-b0c5-60212a761a95.png)\n",
    "\n",
    "De este modo, al pasar el cursor sobre algún elemento de la página, se irá sombreando este mismo y además, el fragmento de código al que corresponde:\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/92232878/182716574-af4c9283-f139-4f84-80eb-4f4753118fbe.png)\n",
    "\n",
    "Con las herramientas de desarrollador abiertas, presionamos **control + F** para abrir la celda **XPath**:\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/92232878/182716874-247a70f9-8e63-4bd0-96d6-94a3cf89f501.png)\n",
    "\n",
    "Es aquí donde iremos introduciendo las expresiones nesesarias según nuestro objetivo. Para extraer los títulos y textos de las noticias en la página, introducimos la siguiente expresión: **//div[@class=\"teaser__copy-container\"]**\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/92232878/182717815-4089ce40-d36b-4bf5-a4a9-5dc66f568298.png)\n",
    "\n",
    "Podemos notar que al dar enter, marca la etiqueta a la que estamos haciendo referencia. Incluso muestra que, este caso, son 63 los nodos que cuentan con una noticia.\n",
    "\n",
    "## XPath en el script de Python\n",
    "\n",
    "En el script del **chromedriver** hecho anteriormente, haremos que este driver ejecute la expresión **XPhat** (imagen del código **html** al final):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Importaciones necesarias\n",
    "\"\"\"\n",
    "from importlib.resources import path\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "# Definimos la variable que almacena el link de la página de interés\n",
    "website = \"https://www.thesun.co.uk/sport/football/\"\n",
    "# creamos el obj path con la ruta del chromedrive que descargamos\n",
    "path = \"C:/Users/Carlos Giles/Documents/Herramientas/chromedriver\"\n",
    "\n",
    "# variable con la función que abrirá el path\n",
    "service=Service(executable_path=path)\n",
    "#varuabe con la función de selenium que usa al webdriver\n",
    "driver=webdriver.Chrome(service=service)\n",
    "#se ejecuta con get y abre el link de la variable website\n",
    "driver.get(website)\n",
    "\"\"\"\n",
    "El método find.element() permite ubicar elementos dentro de la página, haremos que el\n",
    "driver creado anterirmente lo ejecute. Este método necesita dos parámetros, \"by\" que define el método de busqueda y \"value\"\n",
    "para la expresión\n",
    "\"\"\"\n",
    "#driver.find_element(by=\"xpath\", value='//div[@class=\"teaser__copy-container\"]')\n",
    "\"\"\"\n",
    "La linea de código de arriba se comentó para remarcar que, debido a que el XPath en la herramienta de desarrollador marca \n",
    "63 resultados, debemos usar el método find_elments y no find_element ya que solo encontraría el primer elemento. Element\n",
    "devuelve un valor y elements devuelve una lista\n",
    "\"\"\"\n",
    "driver.find_elements(by=\"xpath\", value='//div[@class=\"teaser__copy-container\"]')\n",
    "#Para extraer el siguiente nivel, texto de título y subtítulo modificamos el xpath\n",
    "#driver.find_elements(by=\"xpath\", value='//div[@class=\"teaser__copy-container\"]/a/h2')\n",
    "\"\"\"|\n",
    "Nuevamente se ha comentado la línea de código anterior para hacer notar lo siguiente:\n",
    "La línea de código es correcta pero se puede optimizar ya que antes de /a/h2 la\n",
    "expresión es la misma. Por ello se almacenará en una variable la parte del xpath que \n",
    "no cambia \n",
    "\"\"\"\n",
    "containers=driver.find_elements(by=\"xpath\", value='//div[@class=\"teaser__copy-container\"]')\n",
    "#bucle para composición\n",
    "for container in containers:\n",
    "    #en este punto container=containers, el ./ indica que se usa lo que hay en el mismo container\n",
    "    titulo=container.find_element(by=\"xpath\", value='./a/h2').text\n",
    "    \"\"\" \n",
    "    .=//div[@class=\"teaser__copy-container\"\n",
    "    finds_elements cambia a find_element ya que se hace uno p/c container en containers\n",
    "    \"\"\"\n",
    "    #el subtitulo sigue siendo hijo de \"a\" por eso solo modificamos \"h2\"\n",
    "    subtitulo=container.find_element(by=\"xpath\", value='./a/p').text\n",
    "    #para obtener el link de cada noticia\n",
    "    link=container.find_element(by=\"xpath\", value='./a').get_attribute(\"href\")\n",
    "\n",
    "# ATENCIÓN\n",
    "\"\"\"\n",
    "SE RECOMIENDA NO EJECUTAR ESTE SCRIPT HASTA LOS SIGUINTES NOTEBOOKS\n",
    "\"\"\"\n",
    "# ATENCIÓN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El código **html** por el que navegamos es:\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/92232878/182915611-f7d6a694-55ea-4e7f-9b32-0fc1a4a93fba.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0f1e7454989977e67024e29629c272aec4481f16d732c3b04e0afc459660b12c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
